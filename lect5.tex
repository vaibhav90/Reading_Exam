\newpage
\section{Privacy-Preserving Deep Learning~\cite{Shokri:2015:PDL:2810103.2813687}}~\label{lect5}

\subsubsection*{Context}

Today, commercial companies such as Facebook, Google and Apple collect a large amount of user data to learn 
about user preferences and suggest recommendations. This requires a large amount of data related to the users, 
a considerable part of which is highly sensitive personal information. This data is used to formulate user specific 
models, generation of which is aided by techniques such as deep learning. On the other hand, biomedical and 
clinical researchers cannot attain benefits from these techniques as they are not permitted to share the data. As 
a result privacy and confidentiality restrictions reduce utility. 

\subsubsection*{Problem}

Deep learning presents a interesting avenue to extract highly accurate models by deriving complex features from high
dimensional data. Although such accurate models can give rise to high utility applications, they present serious
privacy issues due to user data stored in servers, which is also used for monetary gains by these companies. As 
a result, there is a need to alter these model generation techniques to offer a satisfactory point between utility
and privacy tradeoff.

\subsubsection*{Contributions}

The authors devise a distributed deep learning technique that collaborates with multiple participants to learn a 
neural-network model on their own inputs, without explicitly sharing these inputs. The key contributions can be 
summarised as follows.

\begin{itemize}
	\item A selective parameter update model: During training iterations, some attributes contribute largely
	towards a neural networks objective function as compared to others. This model selects parameters whose
	current value is far away from the local optima. Only these parameters are updated collaboratively to 
	undergo bigger changes in subsequent iterations. 
	
	\item Distributed collaborative learning: After every iteration of local training, participants
	asynchronously share the computed gradients with each other. Therefore benefiting from each others
	training data without actually sharing it. Thus preserving the privacy of the participants.  
	
\end{itemize}

\subsubsection*{Approach}

The system architecture consists of a local training database for performing the training locally
and parameter server that can be an actual server or a distributed system for running the parameter 
and gradient exchange protocol. 

\begin{itemize}

	\item Each participant maintains a local vector of neural network parameters. A training iteration
	is performed over the local training data. Next, the participant downloads the parameters uploaded 
	on the server and computes the gradient of each parameter. 
	
	\item The parameter server initialises the parameter vector and handles the participants upload and 
	download requests. 
	
	\item While training alone, every participant is more likely 
	to converge to a local optima. However using a distributed approach in learning, by using parameters
	trained on different datasets, can help to escape local optima resulting in more accurate models. 
	
	\item The authors assume round robin to run the gradient decent 
	sequentially. Every participant downloads the most updated parameters from the server, runs local 
	training and uploads selected gradients and the next participant follows in some fixed order. 
	
	\item The authors implemented distributed gradient decent with round robin, random order, and 
	asynchronous parameter exchange protocols. The results were compared with two scenarios, running 
	a gradient descent on the entire dataset and the other is standalone gradient descent where participants 
	train only on their own training data without collaboration. The evaluation was performed on two major 
	datasets used as benchmarks in deep-learning. 
	
\end{itemize}

\subsubsection*{Discussion} 

\begin{itemize}
	\item The authors achieved the same accuracy as simple stochastic gradient decent as compared to gradient 
	descent ran by sharing only a small fraction of gradients at each iteration step. 	
	
	\item The results obtained show that even at sharing only 1 percent of parameters, results in higher accuracy
	than standalone or centralised learning. 
	
	\item Distributed gradient descent using round robin parameter resulted in the highest accuracy and was discovered 
	that round robin protocol is suitable for scenarios where all participants have similar computational capacity. 
	
	\item It was also observed that number of participants has a lower impact on accuracy than the percentage of shared
	parameters. Assuming each participant shares his largest gradients with other participants.
	
	\item The system computes the differential privacy of each parameter and than decides which one to share with other 
	participants resulting in lower privacy leakage. Further, the authors find the sensitivity index for each parameter, 	
	quantifying the amount of random noise which needs to be added to achieve a certain level of differential privacy.
	
	\item The experiments conducted in the paper are based on supervised learning, it would be interesting to evaluate 
	the accuracy of distributed stochastic gradient descent on unsupervised learning approaches. 
	
\end{itemize}
